# Nginx

(1).Fastcgi调优

　　FastCGI全称快速通用网关接口（FastCommonGatewayInterface），可以认为FastCGI是静态服务和动态服务的一个接口。FastCGI像是一个常驻(long-live)型的CGI，它可以一直执行着，只要激活后，不会每次都要花费时间去fork一次(这是CGI最为人诟病的fork-and-execute 模式)。它还支持分布式的运算, 即 FastCGI 程序可以在网站服务器以外的主机上执行并且接受来自其它网站服务器来的请求。

　　FastCGI是语言无关的、可伸缩架构的CGI开放扩展，其主要行为是将CGI解释器进程保持在内存中并因此获得较高的性能。众所周知，CGI解释器的反复加载是CGI性能低下的主要原因，如果CGI解释器保持在内存中并接受FastCGI进程管理器调度，则可以提供良好的性能、伸缩性、Fail- Over特性等等。

　　通用网关接口（Common Gateway Interface，CGI）是Web 服务器运行时外部程序的规范，按CGI 编写的程序可以扩展服务器功能。CGI 应用程序能与浏览器进行交互，还可通过数据API与数据库服务器等外部数据源进行通信，从数据库服务器中获取数据。格式化为HTML文档后，发送给浏览器，也可以将从浏览器获得的数据放到数据库中。几乎所有服务器都支持CGI，可用任何语言编写CGI，包括流行的C、C ++、VB 和Delphi 等。CGI分为标准CGI和间接CGI两种。标准CGI使用命令行参数或环境变量表示服务器的详细请求，服务器与浏览器通信采用标准输入输出方式。间接CGI又称缓冲CGI，在CGI程序和CGI接口之间插入一个缓冲程序，缓冲程序与CGI接口间用标准输入输出进行通信。

　　FastCGI模块官方文档：http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html

　　这里的buffer是读取缓存区，cache是写入缓存区。并且FastCGI可以定义全局的（定义在http{}下），也可以定义局部的（定义在location{}下）。常用参数如下：

```
fastcgi_connect_timeout 300; #指定链接到后端FastCGI的超时时间。``fastcgi_send_timeout 300; #向FastCGI传送请求的超时时间，这个值是指已经完成两次握手后向FastCGI传送请求的超时时间。``fastcgi_read_timeout 300; #指定接收FastCGI应答的超时时间，这个值是指已经完成两次握手后接收FastCGI应答的超时时间。``fastcgi_buffer_size 64k; #指定读取FastCGI应答第一部分需要用多大的缓冲区，这个值表示将使用1个64KB的缓冲区读取应答的第一部分（应答头），可以设置为fastcgi_buffers选项指定的缓冲区大小。``fastcgi_buffers 4 64k; #指定本地需要用多少和多大的缓冲区来缓冲FastCGI的应答请求，如果一个php脚本所产生的页面大小为256KB，那么会分配4个64KB的缓冲区来缓存，如果页面大小大于256KB，``那么大于256KB的部分会缓存到fastcgi_temp指定的路径中，但是这并不是好方法，因为内存中的数据处理速度要快于磁盘。一般这个值应该为站点中php脚本所产生的页面大小的中间值，``如果站点大部分脚本所产生的页面大小为256KB，那么可以把这个值设置为“8 16K”、“4 64k”等。``fastcgi_busy_buffers_size 128k; #建议设置为fastcgi_buffer的两倍，繁忙时候的buffer。``fastcgi_temp_file_write_size 128k; #在写入fastcgi_temp_path时将用多大的数据库，默认值是fastcgi_buffers的两倍，设置上述数值设置小时若负载上来时可能报502Bad Gateway。``fastcgi_temp_path [地址] [目录层级，最高3级，例如2层则为``'1 2'``]; #定义临时文件的路径，目录层级间使用空格隔开``fastcgi_cache ngnix; #表示开启FastCGI缓存并为其指定一个名称。开启缓存非常有用，可以有效降低CPU的负载，并且防止502的错误发生，但是开启缓存也可能会引起其他问题，要很据具体情况选择。``fastcgi_cache_valid 200 302 1h; #用来指定应答代码的缓存时间，实例中的值表示将200和302应答缓存一小时，要和fastcgi_cache配合使用。``fastcgi_cache_valid 301 1d; #将301应答缓存一天。``fastcgi_cache_valid any 1m; #将其他应答缓存为1分钟。``fastcgi_cache_min_uses 1; #请求的数量。``fastcgi_cache_path #定义缓存的路径和其他参数。
```

　　详细说明下fastcgi_cache_path：

　　　　fastcgi_cache_psth [缓存地址] [`levels`=`levels（目录层级）`] [`use_temp_path`=`on`|`off`] `keys_zone`=`name`:`size（定义缓存名称和大小）` [`inactive`=`time（不活跃数据缓存时间）`] [`max_size`=`size（所有缓存的最大总和）`] [`manager_files`=`number`] [`manager_sleep`=`time`] [`manager_threshold`=`time`] [`loader_files`=`number`] [`loader_sleep`=`time`] [`loader_threshold`=`time`] [`purger`=`on`|`off`] [`purger_files`=`number`] [`purger_sleep`=`time`] [`purger_threshold`=`time`];

　　　　缓存的响应首先被写入一个临时文件，然后对该文件进行重命名操作。从0.8.9版本开始，临时文件和缓存文件可以放在不同的文件系统中，不过此时不再是重命名操作，而是文件跨两个文件系统的复制操作。因此建议缓存（fastcgi_cache_path）和临时文件（fastcgi_temp_path）的目录都放在同一文件系统上。如果省略use_temp_path或其值为on，则使用fastcgi_temp_path给定的目录（存放cache第一步生成的临时文件）；如果其值为off，则临时文件放入缓存目录。

　　　　levels设置目录层级，最多三层，层级之间使用冒号隔开。第一层目录名取fastcgi_cache_key md5的最后一个字符，第二层目录名取倒数2-3字符，第三次目录名取倒数4-6字符。例如：fastcgi_cache_key md5为b7f54b2df7773722d382f4809d65029c时，如果levels=1:2，那么c/29/b7f54b2df7773722d382f4809d65029c；如果levels=1:2:3，那么c/29/650/b7f54b2df7773722d382f4809d65029c。

　　定义全局的FastCGI，并在location{}中调用。

```
[root@youxi1 ~]# vim /usr/local/nginx/conf/nginx.conf``http {``......``  ``fastcgi_connect_timeout 300;``  ``fastcgi_send_timeout 300;``  ``fastcgi_read_timeout 300;``  ``fastcgi_buffer_size 64k;``  ``fastcgi_buffers 4 64k;``  ``fastcgi_busy_buffers_size 128k;``  ``fastcgi_temp_file_write_size 128k;``  ``fastcgi_cache_path /data/ngx_fcgi_cache levels=1:2 keys_zone=ngx_fcgi_cache:10m inactive=1d max_size=40g;``  ``server{``......``    ``location ~ \.php$ {``      ``root      html;``      ``fastcgi_pass  127.0.0.1:9000;　　``//将进入到该location的uri请求看做cgi程序，发送到9000端口给php-fpm处理``      ``fastcgi_index index.php;``//动态添加一行fastcgi配置，配置SCRIPT_FILENAME，告知管理进程cgi脚本名称。``      ``fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name;``      ``include    fastcgi_params;　　``//导入fastcgi配置文件``      ``fastcgi_cache ngx_fcgi_cache;　　``//调用fastcgi缓存配置``      ``fastcgi_cache_valid 200 302 1h;　　``//状态码为200、302保存一个小时``      ``fastcgi_cache_valid 301 1d;　　``//状态码为301保存一天``      ``fastcgi_cache_valid any 1m;　　``//其他状态码保存1分钟``      ``fastcgi_cache_min_uses 1;　　``//1次请求后缓存，默认为1``      ``fastcgi_cache_use_stale error timeout invalid_header http_500;　　``//如果出现错误、超时、空或无效的头、状态码500，允许使用陈旧的缓存``      ``fastcgi_cache_key http:``//$host$request_uri;　　//定义缓存的key样式``    ``}``......``  ``}``}
```

　　注意：在整个网络请求的过程中php是一个cgi程序的角色，所以采用名为php-fpm的进程管理程序来对这些被请求的php程序进行管理。fastcgi_pass（发给php-fpm处理）、fastcgi_param（添加动态fastcgi配置）、include（导入fastcgi配置文件）是必不可少的。

(2).gzip压缩网页调优

　　使用gzip压缩功能可以节约带宽，加快传输速率，但是会占用CPU资源。一般需要压缩的内容有：文本、JS、html、CSS，而对于图片、视频、flash不压缩。

　　gzip压缩功能定义在http{}块下，常用参数有如下：

```
gzip ``on``; #开启压缩功能。``gzip_min_length 1k; #设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length（内容长度）中获取，默认值是0，不管页面多大都进行压缩，建议设置成大于1K，如果小与1K可能会越压越大。``gzip_buffers 4 32k; #压缩缓冲区大小，表示申请4个单位为32K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。``gzip_http_version 1.1; #压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可。``gzip_comp_level 9; #压缩比例，用来指定GZIP压缩比，1压缩比最小，处理速度最快，9压缩比最大，传输速度快，但是处理慢，也比较消耗CPU资源。``gzip_types text/css text/xml application/javascript; #用来指定压缩的类型，‘text/html’类型总是会被压缩。``gzip_vary ``on``; #vary header支持，该选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过nginx压缩的数据。
```

　　定义gzip压缩

```
[root@youxi1 ~]# vim /usr/local/nginx/conf/nginx.conf``http{``......``  ``gzip ``on``;``  ``gzip_min_length 1k;``  ``gzip_buffers 4 32k;``  ``gzip_http_version 1.1;``  ``gzip_comp_level 9;``  ``gzip_types text/css text/xml application/javascript;``  ``gzip_vary ``on``;``......``}``[root@youxi1 ~]# /usr/local/nginx/sbin/nginx -t　　``//检查配置文件``nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax ``is` `ok``nginx: configuration file /usr/local/nginx/conf/nginx.conf test ``is` `successful
```

　　可以使用YSLOW查看压缩状况。

(3).expires缓存调优

　　expires缓存主要针对于图片、css、JS等更改机会较少的部分使用，特别是图片，占用带宽大，完全可以设置图片缓存365d。

　　expires缓存定义在location{}中，通过location{}来筛选。

```
[root@youxi1 ~]# vim /usr/local/nginx/conf/nginx.conf``http{``......``  ``server{``  ``......``    ``location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ {缓存图片文件``      ``expires 365d;``    ``}``    ``location ~ .*\.(js|css)$ {　　``//缓存.js和.css文件``      ``expires 10d;``    ``}``    ``location ~ ^/(images|javasdript|js|css|flash|media|``static``){　　``//缓存目录下所有文件``      ``expires 365d;``    ``}``    ``location ~(rebots.txt) {　　``//缓存爬虫协议文件``      ``expires 7d;``      ``break``;``    ``}``  ``}``}``[root@youxi1 ~]# /usr/local/nginx/sbin/nginx -t``nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax ``is` `ok``nginx: configuration file /usr/local/nginx/conf/nginx.conf test ``is` `successful
```

　　expires优点：降低网站带宽，节约成本，提升用户访问体验，减轻服务器压力。

　　expires缺点：被缓存的网页或数据更新时，用户还会使用旧的缓存。

　　缺点处理办法：缩短缓存时间；或更改缓存对面名称。

　　注意：广告图片、网站流量统计工具（监控）、更新频繁的文件不要缓存，或缩短缓存时间。

　　注意：将expires缓存放在一个server{}的最后，否则有可能会出现问题。

(4).日志切割

　　nginx日志切割一般使用脚本文件和计划任务组合来实现的。

　　做一个按天存放，超过10天删除的日志切割计划任务。

```
[root@youxi1 ~]# vim /usr/local/nginx/logs/nginx_cutlog.sh``#!/bin/bash``date=$(date +%F -d -1day)``cd /usr/local/nginx/logs``if` `[ ! -d cut ] ; then　　``//确认是否存在cut目录``  ``mkdir cut``fi``mv access.log cut/access_$(date +%F -d -1day).log``mv error.log cut/error_$(date +%F -d -1day).log``/usr/local/nginx/sbin/nginx -s reload``tar -jcvf cut/$date.tar.bz2 cut/*　　``//打包压缩，注意这里生成在/usr/local/nginx/logs目录下``rm -rf cut/access* && rm -rf cut/error*``find -type f -mtime +10 | xargs rm -rf　　``//删除超过十天的文件``[root@youxi1 ~]# crontab -e``0 0 * * * /bin/sh /usr/local/nginx/logs/nginx_cutlog.sh > /dev/``null` `2>&1``[root@youxi1 ~]# chmod +x /usr/local/nginx/logs/nginx_cutlog.sh
```

(5).日志优化

　　健康检查的日志，不用输入到log中，因为这些日志没有意义，我们分析的话只需要分析访问日志，看看一些页面链接，如200，301，404的状态码，在SEO中很重要，而且我们统计PV是页面计算，这些都没有意义，反而消耗了磁盘IO，降低了服务器性能，我们可以屏蔽这些如图片，js，css这些不宜变化的内容。

```
[root@youxi1 ~]# vim /usr/local/nginx/conf/nginx.conf``http{``......``  ``server{``  ``......``#可以在之前的缓存location中添加``    ``location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ {``      ``expires 365d;``      ``access_log off;``    ``}``    ``location ~ .*\.(js|css)$ {``      ``expires 10d;``      ``access_log off;``    ``}``#也可以另外建立一个location``#    location ~ .*\.(js|css|gif|jpg|jpeg|png|bmp|swf)$ {``#      access_log off;``#    }``  ``......``  ``}``}
```

　　另外启用日志格式优化

```
[root@youxi1 ~]# vim /usr/local/nginx/conf/nginx.conf``http{``......``  ``log_format main ``'$remote_addr - $remote_user [$time_local] "$request" '``           ``'$status $body_bytes_sent "$http_referer" '``           ``'"$http_user_agent" "$http_x_forwarded_for"'``;``......``}
```

说明：

　　$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；

　　$remote_user：用来记录客户端用户名称；

　　$time_local：用来记录访问时间与时区；

　　$request：用来记录请求的url与http协议；

　　$status：用来记录请求状态，功是200；

　　$body_bytes_s ent：记录发送给客户端文件主体内容大小；

　　$http_referer：用来记录从哪个页面链接访问过来的；

　　$http_user_agent：记录客户端浏览器的相关信息；

　　日志文件修改所属主和所属组，777权限需要看情况而定。

```
[root@youxi1 ~]# chown -R root.root /usr/local/nginx/logs/``[root@youxi1 ~]# chmod -R 777 /usr/local/nginx/logs/
```

(6).目录文件访问控制和来源访问控制

　　这是location下的两个参数allow和deny的使用，前者允许，后者拒绝。

　　例如，配置/usr/local/nginx/html/images下的.php、.php5、.sh、.py、.pl结尾的文件禁止访问。

```
[root@youxi1 ~]# vim /usr/local/nginx/conf/nginx.conf``http{``......``  ``server{``  ``......``    ``location ~ ^/images/.*\.(php|php5|sh|py|pl)$ {``      ``deny all;``    ``}   ......``  ``}``}``[root@youxi1 ~]# /usr/local/nginx/sbin/nginx -t   ``nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax ``is` `ok``nginx: configuration file /usr/local/nginx/conf/nginx.conf test ``is` `successful``[root@youxi1 ~]# /usr/local/nginx/sbin/nginx -s reload``[root@youxi1 ~]# mkdir /usr/local/nginx/html/images``[root@youxi1 ~]# echo ``""` `> /usr/local/nginx/html/images/index.php
```

　　注意：由于同优先级的location自上而下执行，所以不允许要在允许之前，否则不会生效。expires缓存放在一个server{}的最后。

1、Nginx运行工作进程数量
Nginx运行工作进程个数一般设置CPU的核心或者核心数x2。如果不了解cpu的核数，可以top命令之后按1看出来，也可以查看/proc/cpuinfo文件 grep ^processor /proc/cpuinfo | wc -l
[root@lx~]# vi/usr/local/nginx1.10/conf/nginx.conf worker_processes 4*;* [root@lx~]# /usr/local/nginx1.10/sbin/nginx-s reload [root@lx~]# ps -aux | grep nginx |grep -v grep root 9834 0.0 0.0 47556 1948 ? Ss 22:36 0:00 nginx: master processnginx www 10135 0.0 0.0 50088 2004 ? S 22:58 0:00 nginx: worker process www 10136 0.0 0.0 50088 2004 ? S 22:58 0:00 nginx: worker process www 10137 0.0 0.0 50088 2004 ? S 22:58 0:00 nginx: worker process www 10138 0.0 0.0 50088 2004 ? S 22:58 0:00 nginx: worker process
2、Nginx运行CPU亲和力
比如4核配置：
worker_processes 4; worker_cpu_affinity 0001 0010 0100 1000
比如8核配置：
worker_processes 8; worker_cpu_affinity 00000001 00000010 00000100 0000100000010000 00100000 01000000 10000000;
worker_processes最多开启8个，8个以上性能提升不会再提升了，而且稳定性变得更低，所以8个进程够用了。
3、Nginx最大打开文件数
worker_rlimit_nofile 65535*;*
这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n的值保持一致。
注：文件资源限制的配置可以在/etc/security/limits.conf设置，针对root/user等各个用户或者*代表所有用户来设置。
\* soft nofile 65535 * hard nofile 65535
用户重新登录生效（ulimit -n）
4、Nginx事件处理模型
events { use epoll; worker_connections 65535; multi_accept on; }
nginx采用epoll事件模型，处理效率高。
work_connections是单个worker进程允许客户端最大连接数，这个数值一般根据服务器性能和内存来制定，实际最大值就是worker进程数乘以work_connections。
实际我们填入一个65535，足够了，这些都算并发值，一个网站的并发达到这么大的数量，也算一个大站了！
multi_accept 告诉nginx收到一个新连接通知后接受尽可能多的连接，默认是on，设置为on后，多个worker按串行方式来处理连接，也就是一个连接只有一个worker被唤醒，其他的处于休眠状态，设置为off后，多个worker按并行方式来处理连接，也就是一个连接会唤醒所有的worker，直到连接分配完毕，没有取得连接的继续休眠。当你的服务器连接数不多时，开启这个参数会让负载有一定的降低，但是当服务器的吞吐量很大时，为了效率，可以关闭这个参数。
5、开启高效传输模式
http { include mime.types; default_type application/octet-stream; …… sendfile on; tcp_nopush on; …… }

- Include mime.types ：媒体类型,include 只是一个在当前文件中包含另一个文件内容的指令。
- default_type application/octet-stream ：默认媒体类型足够。
- sendfile on：开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。
- tcp_nopush on：必须在sendfile开启模式才有效，防止网路阻塞，积极的减少网络报文段的数量（将响应头和正文的开始部分一起发送，而不一个接一个的发送。）

6、连接超时时间
主要目的是保护服务器资源，CPU，内存，控制连接数，因为建立连接也是需要消耗资源的。
keepalive_timeout 60; tcp_nodelay on; client_header_buffer_size 4k; open_file_cache max=102400 inactive=20s; open_file_cache_valid 30s; open_file_cache_min_uses 1; client_header_timeout 15; client_body_timeout 15; reset_timedout_connection on; send_timeout 15; server_tokens off; client_max_body_size 10m;

- keepalived_timeout ：客户端连接保持会话超时时间，超过这个时间，服务器断开这个链接。
- tcp_nodelay：也是防止网络阻塞，不过要包涵在keepalived参数才有效。
- client_header_buffer_size 4k：客户端请求头部的缓冲区大小，这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过 1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。
- open_file_cache max=102400 inactive=20s ：这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive 是指经过多长时间文件没被请求后删除缓存。
- open_file_cache_valid 30s：这个是指多长时间检查一次缓存的有效信息。
- open_file_cache_min_uses 1 ：open_file_cache指令中的inactive 参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive 时间内一次没被使用，它将被移除。
- client_header_timeout ：设置请求头的超时时间。我们也可以把这个设置低些，如果超过这个时间没有发送任何数据，nginx将返回request time out的错误。
- client_body_timeout设置请求体的超时时间。我们也可以把这个设置低些，超过这个时间没有发送任何数据，和上面一样的错误提示。
- reset_timeout_connection ：告诉nginx关闭不响应的客户端连接。这将会释放那个客户端所占有的内存空间。
- send_timeout ：响应客户端超时时间，这个超时时间仅限于两个活动之间的时间，如果超过这个时间，客户端没有任何活动，nginx关闭连接。
- server_tokens ：并不会让nginx执行的速度更快，但它可以关闭在错误页面中的nginx版本数字，这样对于安全性是有好处的。
- client_max_body_size：上传文件大小限制。

7、fastcgi 调优
fastcgi_connect_timeout 600; fastcgi_send_timeout 600; fastcgi_read_timeout 600; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; fastcgi_temp_path/usr/local/nginx1.10/nginx_tmp; fastcgi_intercept_errors on; fastcgi_cache_path/usr/local/nginx1.10/fastcgi_cache levels=1:2 keys_zone=cache_fastcgi:128minactive=1d max_size=10g;

- fastcgi_connect_timeout 600 ：指定连接到后端FastCGI的超时时间。
- fastcgi_send_timeout 600 ：向FastCGI传送请求的超时时间。
- fastcgi_read_timeout 600 ：指定接收FastCGI应答的超时时间。
- fastcgi_buffer_size 64k ：指定读取FastCGI应答第一部分需要用多大的缓冲区，默认的缓冲区大小为。fastcgi_buffers指令中的每块大小，可以将这个值设置更小。
- fastcgi_buffers 4 64k ：指定本地需要用多少和多大的缓冲区来缓冲FastCGI的应答请求，如果一个php脚本所产生的页面大小为256KB，那么会分配4个64KB的缓冲区来缓存，如果页面大小大于256KB，那么大于256KB的部分会缓存到fastcgi_temp_path指定的路径中，但是这并不是好方法，因为内存中的数据处理速度要快于磁盘。一般这个值应该为站点中php脚本所产生的页面大小的中间值，如果站点大部分脚本所产生的页面大小为256KB，那么可以把这个值设置为“8 32K”、“4 64k”等。
- fastcgi_busy_buffers_size 128k ：建议设置为fastcgi_buffers的两倍，繁忙时候的buffer。
- fastcgi_temp_file_write_size 128k ：在写入fastcgi_temp_path时将用多大的数据块，默认值是fastcgi_buffers的两倍，该数值设置小时若负载上来时可能报502BadGateway。
- fastcgi_temp_path ：缓存临时目录。
- fastcgi_intercept_errors on ：这个指令指定是否传递4xx和5xx错误信息到客户端，或者允许nginx使用error_page处理错误信息。注：静态文件不存在会返回404页面，但是php页面则返回空白页！
- fastcgi_cache_path /usr/local/nginx1.10/fastcgi_cachelevels=1:2 keys_zone=cache_fastcgi:128minactive=1d max_size=10g ：fastcgi_cache缓存目录，可以设置目录层级，比如1:2会生成16*256个子目录，cache_fastcgi是这个缓存空间的名字，cache是用多少内存（这样热门的内容nginx直接放内存，提高访问速度），inactive表示默认失效时间，如果缓存数据在失效时间内没有被访问,将被删除，max_size表示最多用多少硬盘空间。
- fastcgi_cache cache_fastcgi ：#表示开启FastCGI缓存并为其指定一个名称。开启缓存非常有用，可以有效降低CPU的负载，并且防止502的错误放生。cache_fastcgi为proxy_cache_path指令创建的缓存区名称。
- fastcgi_cache_valid 200 302 1h ：#用来指定应答代码的缓存时间，实例中的值表示将200和302应答缓存一小时，要和fastcgi_cache配合使用。
- fastcgi_cache_valid 301 1d ：将301应答缓存一天。
- fastcgi_cache_valid any 1m ：将其他应答缓存为1分钟。
- fastcgi_cache_min_uses 1 ：该指令用于设置经过多少次请求的相同URL将被缓存。
- fastcgi_cache_key http://$host$request_uri ：该指令用来设置web缓存的Key值,nginx根据Key值md5哈希存储.一般根据$host(域名)、$request_uri(请求的路径)等变量组合成proxy_cache_key 。
- fastcgi_pass ：指定FastCGI服务器监听端口与地址，可以是本机或者其它。

**总结：**
nginx的缓存功能有：proxy_cache / fastcgi_cache

- proxy_cache的作用是缓存后端服务器的内容，可能是任何内容，包括静态的和动态。
- fastcgi_cache的作用是缓存fastcgi生成的内容，很多情况是php生成的动态的内容。
- proxy_cache缓存减少了nginx与后端通信的次数，节省了传输时间和后端宽带。
- fastcgi_cache缓存减少了nginx与php的通信的次数，更减轻了php和数据库(mysql)的压力。

8、gzip 调优
使用gzip压缩功能，可能为我们节约带宽，加快传输速度，有更好的体验，也为我们节约成本，所以说这是一个重点。
Nginx启用压缩功能需要你来ngx_http_gzip_module模块，apache使用的是mod_deflate。
一般我们需要压缩的内容有：文本，js，html，css，对于图片，视频，flash什么的不压缩，同时也要注意，我们使用gzip的功能是需要消耗CPU的！
gzip on; gzip_min_length 2k; gzip_buffers 4 32k; gzip_http_version 1.1; gzip_comp_level 6; gzip_typestext/plain text/css text/javascriptapplication/json application/javascript application/x-javascriptapplication/xml; gzip_vary on; gzip_proxied any; gzip on; *#开启压缩功能*

- gzip_min_length 1k ：设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取，默认值是0，不管页面多大都进行压缩，建议设置成大于1K，如果小与1K可能会越压越大。

- gzip_buffers 4 32k ：压缩缓冲区大小，表示申请4个单位为32K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。

- gzip_http_version 1.1 ：压缩版本，用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可。

- gzip_comp_level 6 ：压缩比例，用来指定GZIP压缩比，1压缩比最小，处理速度最快，9压缩比最大，传输速度快，但是处理慢，也比较消耗CPU资源。

- gzip_types text/css text/xml application/javascript ：用来指定压缩的类型，‘text/html’类型总是会被压缩。默认值: gzip_types text/html (默认不对js/css文件进行压缩)

- - 压缩类型，匹配MIME型进行压缩；
  - 不能用通配符 text/*；
  - text/html默认已经压缩 (无论是否指定)；
  - 设置哪压缩种文本文件可参考 conf/mime.types。

- gzip_vary on ：varyheader支持，改选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过nginx压缩的数据。

9、expires 缓存调优
缓存，主要针对于图片，css，js等元素更改机会比较少的情况下使用，特别是图片，占用带宽大，我们完全可以设置图片在浏览器本地缓存365d，css，js，html可以缓存个10来天，这样用户第一次打开加载慢一点，第二次，就非常快了！缓存的时候，我们需要将需要缓存的拓展名列出来， Expires缓存配置在server字段里面。
location ~* .(ico|jpe?g|gif|png|bmp|swf|flv)$ { expires 30d; *#log_not_found off;* access_log off; } location ~* .(js|css)$ { expires 7d; log_not_found off; access_log off; }
注：log_not_found off;是否在error_log中记录不存在的错误。默认是。
总结：
expire功能优点：

- expires可以降低网站购买的带宽，节约成本；
- 同时提升用户访问体验；
- 减轻服务的压力，节约服务器成本，是web服务非常重要的功能。

expire功能缺点：

- 被缓存的页面或数据更新了，用户看到的可能还是旧的内容，反而影响用户体验。

解决办法：第一个缩短缓存时间，例如：1天，但不彻底，除非更新频率大于1天；第二个对缓存的对象改名。
网站不希望被缓存的内容：

- 网站流量统计工具；
- 更新频繁的文件（google的logo）。

10、防盗链
防止别人直接从你网站引用图片等链接，消耗了你的资源和网络流量，那么我们的解决办法由几种：

1. 水印，品牌宣传，你的带宽，服务器足够；
2. 防火墙，直接控制，前提是你知道IP来源；
3. 防盗链策略下面的方法是直接给予404的错误提示。

location ~*^.+.(jpg|gif|png|swf|flv|wma|wmv|asf|mp3|mmf|zip|rar)$ { valid_referers noneblocked [http://www.benet.com](http://www.benet.com/) benet.com; if($invalid_referer) { #return 302 http://www.benet.com/img/nolink.jpg; return 404; break; } access_log off; }
参数可以使如下形式：

- none ：意思是不存在的Referer头(表示空的，也就是直接访问，比如直接在浏览器打开一个图片)。
- blocked ：意为根据防火墙伪装Referer头，如：“Referer:XXXXXXX”。
- server_names ：为一个或多个服务器的列表，0.5.33版本以后可以在名称中使用“*”通配符。

11、内核参数优化

- fs.file-max = 999999：这个参数表示进程（比如一个worker进程）可以同时打开的最大句柄数，这个参数直线限制最大并发连接数，需根据实际情况配置。
- net.ipv4.tcp_max_tw_buckets = 6000 ：这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。该参数默认为180000，过多的TIME_WAIT套接字会使Web服务器变慢。注：主动关闭连接的服务端会产生TIME_WAIT状态的连接
- net.ipv4.ip_local_port_range = 1024 65000 ：允许系统打开的端口范围。
- net.ipv4.tcp_tw_recycle = 1 ：启用timewait快速回收。
- net.ipv4.tcp_tw_reuse = 1 ：开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接。这对于服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接。
- net.ipv4.tcp_keepalive_time = 30：这个参数表示当keepalive启用时，TCP发送keepalive消息的频度。默认是2小时，若将其设置的小一些，可以更快地清理无效的连接。
- net.ipv4.tcp_syncookies = 1 ：开启SYN Cookies，当出现SYN等待队列溢出时，启用cookies来处理。
- net.core.somaxconn = 40960 ：web 应用中 listen 函数的 backlog 默认会给我们内核参数的。
- net.core.somaxconn ：限制到128，而nginx定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。注：对于一个TCP连接，Server与Client需要通过三次握手来建立网络连接.当三次握手成功后,我们可以看到端口的状态由LISTEN转变为ESTABLISHED,接着这条链路上就可以开始传送数据了.每一个处于监听(Listen)状态的端口,都有自己的监听队列.监听队列的长度与如somaxconn参数和使用该端口的程序中listen()函数有关。somaxconn定义了系统中每一个端口最大的监听队列的长度,这是个全局的参数,默认值为128，对于一个经常处理新连接的高负载 web服务环境来说，默认的 128 太小了。大多数环境这个值建议增加到 1024 或者更多。大的侦听队列对防止拒绝服务 DoS 攻击也会有所帮助。
- net.core.netdev_max_backlog = 262144 ：每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。
- net.ipv4.tcp_max_syn_backlog = 262144 ：这个参数标示TCP三次握手建立阶段接受SYN请求队列的最大长度，默认为1024，将其设置得大一些可以使出现Nginx繁忙来不及accept新连接的情况时，Linux不至于丢失客户端发起的连接请求。
- net.ipv4.tcp_rmem = 10240 87380 12582912 ：这个参数定义了TCP接受缓存（用于TCP接受滑动窗口）的最小值、默认值、最大值。
- net.ipv4.tcp_wmem = 10240 87380 12582912：这个参数定义了TCP发送缓存（用于TCP发送滑动窗口）的最小值、默认值、最大值。
- net.core.rmem_default = 6291456：这个参数表示内核套接字接受缓存区默认的大小。
- net.core.wmem_default = 6291456：这个参数表示内核套接字发送缓存区默认的大小。
- net.core.rmem_max = 12582912：这个参数表示内核套接字接受缓存区的最大大小。
- net.core.wmem_max = 12582912：这个参数表示内核套接字发送缓存区的最大大小。
- net.ipv4.tcp_syncookies = 1：该参数与性能无关，用于解决TCP的SYN攻击。

## Nginx 动静分离

# Tomcat

## 修改Tomcat连接器修改为NIO

1）BIO：一个线程处理一个请求。缺点：并发量高时，线程数较多，浪费资源。Tomcat7或以下在Linux系统中默认使用这种方式。

2）NIO：利用Java的异步IO处理，可以通过少量的线程处理大量的请求。Tomcat8在Linux系统中默认使用这种方式。Tomcat7必须修改Connector配置来启动（conf/server.xml配置文件）：

3）APR(Apache Portable Runtime)：从操作系统层面解决io阻塞问题。Linux如果安装了apr和native，Tomcat直接启动就支持apr。

3.2、apr模式

安装apr以及tomcat-native

yum -y install apr apr-devel

进入tomcat/bin目录，比如：

cd /opt/local/tomcat/bin/ tar xzfv tomcat-native.tar.gz cd tomcat-native-1.1.32-src/jni/native ./configure --with-apr=/usr/bin/apr-1-config make && make install

\#注意最新版本的tomcat自带tomcat-native.war.gz，不过其版本相对于yum安装的apr过高，configure的时候会报错。

解决：yum remove apr apr-devel –y,卸载yum安装的apr和apr-devel,下载最新版本的apr源码包，编译安装;或者下载低版本的tomcat-native编译安装

安装成功后还需要对tomcat设置环境变量，方法是在catalina.sh文件中增加1行：

CATALINA_OPTS="-Djava.library.path=/usr/local/apr/lib"

\#apr下载地址：http://apr.apache.org/download.cgi

\#tomcat-native下载地址：http://tomcat.apache.org/download-native.cgi

修改8080端对应的conf/server.xml

protocol="org.apache.coyote.http11.Http11AprProtocol"

```xml
<Connector executor="tomcatThreadPool" port="8080" protocol="org.apache.coyote.http11.Http11AprProtocol" connectionTimeout="20000" enableLookups="false" redirectPort="8443" URIEncoding="UTF-8" />
```

PS:启动以后查看日志 显示如下表示开启 apr 模式

Sep 19, 2016 3:46:21 PM org.apache.coyote.AbstractProtocol start INFO: Starting ProtocolHandler ["http-apr-8081"]

## Tomact运行模式禁用AJP连接器

AJP的全称 Apache JServer Protocol，使用 Nginx+Tomca t的架构，所以用不着 AJP 协议，所以把AJP连接器禁用。

## 调整JVM的内存

Tomcat 是运行在 JVM 上的，所以对 JVM 的调优也是非常有必要的。

找到 catalina.sh；

```xml
JAVA_OPTS="-Djava.awt.headless=true -Dfile.encoding=UTF-8-server -Xms1024m -Xmx4096m -XX:NewSize=512m -XX:MaxNewSize=512m -XXermSize=512m -XX:MaxPermSize=512m -XX:+DisableExplicitGC"
```

调整堆大小的的目的是最小化垃圾收集的时间，以在特定的时间内最大化处理客户的请求。

• -server：启用jdk的server版本。 • -Xms：虚拟机初始化时的最小堆内存。 • -Xmx：虚拟机可使用的最大堆内存。 #-Xms与-Xmx设成一样的值，避免JVM因为频繁的GC导致性能大起大落 • -XX:PermSize：设置非堆内存初始值,默认是物理内存的1/64。 • -XX:MaxNewSize：新生代占整个堆内存的最大值。 • -XX:MaxPermSize：Perm（俗称方法区）占整个堆内存的最大值，也称内存最大永久保留区域。

-XX:PermSize设置非堆内存初始值，默认是物理内存的1/64 。

-XX:MaxPermSize设置最大非堆内存的大小，默认是物理内存的1/4。

> 参考https://tomcat.apache.org/tomcat-8.0-doc/config/executor.htmlhttps://tomcat.apache.org/tomcat-8.0-doc/config/index.html

## 调整Tomcat线程池

```xml
<Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
    maxThreads="500" minSpareThreads="20" maxThreads="600000"/>
```
name：给执行器（线程池）起一个名字；

namePrefix：指定线程池中的每一个线程的 name 前缀；

maxThreads：线程池中最大的线程数量，假设请求的数量超过了 750，这将不是意味着将 maxThreads 属性值设置为 750，它的最好解决方案是使用「Tomcat集群」。也就是说，如果有 1000 请求，两个 Tomcat 实例设置 maxThreads = 500，而不在单 Tomcat 实例的情况下设置 maxThreads=1000。

minSpareThreads：线程池中允许空闲的线程数量（多余的线程都杀死）；

maxIdLeTime：一个线程空闲多久算是一个空闲线程；

注：当tomcat并发用户量大的时候，单个jvm进程确实可能打开过多的文件句柄，这时会报java.net.SocketException:Too many open files错误。可使用下面步骤检查：

• ps -ef |grep tomcat 查看tomcat的进程ID，记录ID号，假设进程ID为10001

 • lsof -p 10001|wc -l 查看当前进程id为10001的 文件操作数 

• ulimit -a 查看每个用户允许打开的最大文件数

3、Tomcat Connector三种运行模式（BIO, NIO, APR）

## 调整Tomcat的连接器Connector

```xml
    <Connector executor="tomcatThreadPool" port="8080" protocol="HTTP/1.1"
               connectionTimeout="20000"
               enableLookups="false"
               redirectPort="8443" URIEncoding="UTF-8" />
```

executor：指定这个连接器所使用的执行器（线程池）；

enableLookups=false：关闭 DNS 解析，减少性能损耗；

minProcessors：服务器启动时创建的最少线程数；

maxProcessors：最大可以创建的线程数；

acceptCount=1000：线程池中的线程都被占用，允许放到队列中的请求数；

maxThreads=500：最大线程数；

minSpareThreads=20：最小空闲线程数，这里是一直会运行的线程；

maxSpareThreads : 如果空闲状态的线程数多于设置的数目，则将这些线程中止，减少这个池中的线程总数。

connectionTimeout : connectionTimeout为网络连接超时时间毫秒数。

URIEncoding=”UTF-8″ :使得tomcat可以解析含有中文名的文件的url，真方便，不像apache里还有搞个mod_encoding，还要手工编译





# MySql

## SQL

避免函数索引

SELECT * FROM t WHERE YEAR(d) >= 2016;

由于MySQL不像Oracle那样支持函数索引，即使d字段有索引，也会直接全表扫描。

应改为----->	SELECT * FROM t WHERE d >= '2016-01-01';

LIKE双百分号无法使用到索引

SELECT * FROM t WHERE name LIKE '%de%';

----->	SELECT * FROM t WHERE name LIKE 'de%';

目前只有MySQL5.7支持全文索引（支持中文）

读取适当的记录LIMIT M,N(偏移量，页显示数量)  查一条就停了

 SELECT * FROM t WHERE 1;

----->	SELECT * FROM t WHERE 1 LIMIT 10;

优化应贯穿整个产品开发周期中，比如编写复杂SQL时查看执行计划，安装MySQL服务器时尽量合理配置(见过太多完全使用默认配置安装的情况)，根据应用负载选择合理的硬件配置等。

**1、性能分析**

性能分析包含多方面：CPU、Memory、磁盘/网络IO、MySQL服务器本身等。

1.1 操作系统分析

常规的操作系统分析，在Linux中通常包含一些性能监控命令，如top、vmstat、iostat、strace、iptraf等。

- **内存：**内存是大项，高查询消耗大量的查询缓存，内存必须足够，并且给系统本身要预留一些。
- **磁盘：**配备高速磁盘+RAID会有更好的读写速度，并且SSD成本逐渐降低，升级成本会在可接受范围。
- **网络：**目前市场上千兆万兆网卡已很常见。
- **CPU：**虽然很多情况下CPU用不完，但也不能让它成为瓶颈。

生产环境的MySQL多数情况部署在Linux系统中，Linux系统本身可以优化的配置并不多。硬件的选型是复杂，涉及计算机组成的原理性知识，需要额外了解。

1.2 MySQL服务性能分析

MySQL服务器的性能通常通过监控命令查看系统工作状态，确定哪些因素成为瓶颈。

**1.2.1 SHOW GLOBAL STATUS**

显示了目前MySQL的工作状态，包含很多参数，下面对一些参数进行说明，其余的参考官方说明：

**1.Aborted_clients**

如果该值随时间增加，检查是否优雅关闭连接，检查max_allowed_packet配置变量是否被超过导致强制中断。

**2.Aborted_connections**

接近于0，检查网络问题，如果有少量是正常的，比如鉴权失败等。

**3.Binlog_cache_disk_use和Binlog_cache_use**

大部分事务应该在缓冲中进行，如果disk cache很大，可考虑增加内存缓存。

**4.Bytes_recevied和Bytes_sent**

如果值很大，检查是否查询超过需要的数据。

**5.Com_\***

尽量让如Com_rollback这些不常见的变量超过预期，用innotop检查。

**6.Create_tmp_tables**

优化查询降低该值。

**7.Handler_read_rnd_next**

Handler_read_rnd_next / Handler_read_rnd显示全表扫面大致平均值，如果很大，只能优化查询。

**8.Open_files**

不应该接近于open_files_limit，如果接近就应该适当增加open_files_limit。

**9.Qcache_\***

查询缓存相关。

**10.Select_full_join**

全联接无索引联接，尽量避免，优化查询。

**11.Select_full_range_join**

值过高说明使用了范围查询联接表，范围查询比较慢，可优化。

**12.Sort_meger_passes**

如果值较大可考虑增加sort_buffer_size，查明是那个查询导致使用文件排序。

**13.Table_locks_waited**

表被锁定导致服务器锁等待，InnoDB的行锁不会使得该变量增加，建议开启慢查询日志。

**14.Threads_created**

如果值在增加，可考虑增加thread_cache_size。

**1.2.2 SHOW ENGINE INNODB STATUS**

暂时的数据包含了太多InnoDB核心信息，并且需要比较深的了解InnoDB引擎工作原理，这里不做过多说明，请查阅针对此的专项文档。

注: 通常包含SEMAPHORES、TRANSACTIONS、FILE I/O、LOG、BUFFER POOL AND MEMORY等一些详细值，有些参数是上一次执行以来的平均值，所以建议隔一段时间再打印一次得到这段时间的统计，有点类似iostat的统计磁盘平均读写一样。

**1.2.3 开启慢查询日志配置**

排查导致MySQL运行缓慢的问题SQL，开启慢查询日志配置，可能有很有帮助：

slow_query_log=1

slow_query_log_file=/YOUR_DIR/mysql_slow.log

配合慢查询日志分析工具(如mysqlsla)

**2、查询性能优化**

一般来说在编写SQL时，注意查询是否能使用到索引，是否在大表中或者高频率查询中引起全表扫描，这些主要通过经验分析配合execution plan得到比较理想的查询消耗。

MySQL查询优化，也可以参考：MySQL：数据库优化，看这篇就够了

2.1 查询基础

了解查询过程，才能知道哪些步骤可能出现瓶颈，execution plan结果也会有所体现，MySQL查询的一般过程：

1. Client往服务器发送查询指令。
2. 服务器查询缓存，如果存在则直接返回，否则下一步。
3. 服务器解析、预处理和优化查询，生成执行计划。
4. 执行引擎调用存储引擎API执行查询。
5. 服务器将结果返回至客户端。

**用图表示如下：**

![img](https:////note.youdao.com/src/D66433EC50A5454FAE7381470F64D717)

**解析与预处理过程:**

- 解析器将查询分解后构造解析树，进行语法解析与验证查询，检查SQL是否有效。
- 预处理器解析语义：如检查表和列是否存在，是否存在歧义等。
- 预处理器检查权限。

**查询优化器:**

该过程比较复杂，将解析树的结果变成执行计划，优化器的任务是寻找最好的方式(但并不是总能选择最好的方案)，MySQL使用基于开销的优化器，预测不同执行计划的开销。

- MySQL不考虑不受它控制的开销，如用户存储过程与用户自定义的函数
- 不考虑正在运行的其他查询

2.2 优化数据访问 (这一点很重要)

1. 应用程序是否获取超过需要的数据量？(PS: 多次遇到过查询表所有数据然后再程序中只读取10行之类的代码)
2. MySQL 服务器是否分析了超过需要的行？数据是否没有在存储引擎层被过来掉？(Using index , Using where)

**典型的错误如下：**

1. 提取超过需要的行，然后在程序中只要一部分 (应该使用limit限制数据量）。
2. 多表join提取所有的列 (应该只读取需要的列)。
3. 提取所有的列（提取不需要的列可能导致优化索引失效，增加磁盘IO，浪费内存等, 但如果是知道这个影响并利用查询缓存，简化设计等也是可以考虑的）。

访问类型：

Full Table Scan > Index Scan > Range Scan > Unique Index Lookup > Constant.

访问速度依次递增。

对于使用where语句来过滤数据的话，最好到最坏的情况是：

1. 对索引查找用where来消除不匹配的数据行，在存储引擎层。
2. 使用覆盖索引 (Extra 为Using Index) 来避免访问行，取得索引数据后过滤行，发生在MySQL服务器层，但不需要读取行数据。
3. 从表中查询数据，然后过滤 (Using Where), 发生在服务器端并且要读取行数据。

后面会针对执行计划结果做详细介绍。

2.3 关于执行计划

执行计划结果样例如下图(也可用其他的可视化工具，如mysql workbench)：

所代表的含义可在官方文档中找到详细说明 ( https://dev.mysql.com/doc/refman/5.5/en/explain-output.html )，

这里说明一些比较重要的结果:

**TYPE字段的值：**

前面所说的访问速度依次递增就和这个有关:

Full Table Scan > Index Scan > Range Scan > Unique Index Lookup > Constant.

这里列出一些常见的说明：

**1、const:** 最多匹配一行, 如 SELECT * FROM rental where rental_id=1。

**2、eq_ref:** 读取的行依次匹配前一个表。

**3、ref:** 连接仅使用左索引或者索引不是PRIMARY或UNIQUE(或者说得到的不是一行的结果)，如果得到的几行数据，这是个比较好的类型。

**4、range:** 使用索引的范围扫描，如使用了 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN()等条件。

**5、index:** 除了索引树被扫描之外，索引连接类型与ALL相同。这有两种方式：

1. 如果索引是查询的覆盖索引，并满足表中所需的所有数据，则仅扫描索引树。在这种情况下，Extra列为Using index。仅索引扫描通常比ALL更快，因为索引的大小通常小于表数据。
2. 使用索引来执行全表扫描，以按索引顺序查找数据行。在Extra列张则没有Using index，这种情况与ALL的区别是ALL是按行扫描。

**6、ALL:** 全表扫描，比较糟糕 (但有时候数据比较少的情况下，MySQL会直接进行全表扫描读取数据，效率更高)。

2.4 优化特定的查询

查询优化的一个办法是迁移旧数据，腾出内存空间重新平衡索引结构，使得更快的查询速度，很多应用保留半年或三个月的数据都能满足需求，对于旧数据，额外提供平台访问或者在应用层做路由。

**2.4.1 优化COUNT (遇到过一知半解的使用，导致想优化却适得其反)**

COUNT有两种不同的工作方式：**统计值的数量和统计行的数量。**

值是一个非空(Non-NULL)的表达式(NULL则表示没有值)，如果在COUNT()中定义了列名或其他表达式，COUNT则会统计这个表达式有值(Non-NULL)的次数。

COUNT另外一种工作方式就是统计行数，当MySQL知道括号中的表达式不会为NULL的时候，则使用这种方式，COUNT(*)是个例子，它不会展开成所有列，则是忽略所以的列并统计。

**2.4.2 优化limit和offset**

偏移量很大的查询代价很高，如LIMIT 10000, 10, 则会产生10010数据，然后只截取10行。

解决办法：

1. 限制分页能读取的数据页数。
2. 可考虑使用覆盖索引，如 select id, name, description from book limit 100,10;

在ID上有索引改进为：select id, name, description from book inner join (select id from book limit 100, 10) as b;

## 数据库的性能瓶颈的原因

​	1.数据库连接数

​	2.单表数据量大

​	  没有索引时，全表扫描

​	  有索引，一般是B+树，实现角度，硬盘级的存储，IO操作，从硬盘把索引加载到内存

​	3.硬件资源QPS/TPS

数据库性能瓶颈解决方案

​	读写分离，优化SQL，索引，缓存(大数据量时可能会有所拖累，因为要从数据库同步到缓存)，分库分表，分区(分库分表的一种)

## 读写分离

​	连接数增加，硬件资源提升

​	区别读写多数据源方式进行数据的存储和加载。数据的存储(增删改)指定写数据源，数据的读取查询指定读数据源

 	读写分离基于主从复制，主从出现延时怎么办？	

 		1.了解主从复制原理，优化  

 		2.应用程序判断主从是否出现延时

## 分库分表——根本上解决性能瓶颈

​	对数据的库表进行拆分，用分片的方式对数据进行管理

​	如何拆分？

​	1.垂直拆分

​	  单库垂直拆分用户库，订单库，账户库...

​	  为什么能解决性能瓶颈？解决了数据库连接数，每个库可以放在不同机器上，提升了硬件资源

​	  优点：业务清新，可移植性好

​	  缺点：多数据库事物，跨库关联查询改为接口查询

​	2.水平拆分

​	  一个大的数据表，拆分为多个表，user表通过id%10分为10个user表

​	  为什么能解决性能瓶颈？解决了数据库连接数，每个表可以放在不同机器上，提升了硬件资源

​	  优点：可以按照日期或者id进行划分规则

​	  缺点：第一次拆分规则确定后，以后不便于更改

数据库中间件都需要做的

  解析SQL——>数据源管理——>数据源分配——>请求/响应——>结果整合

Mycat分库分表中间件

​	开源，数据库集群，支持事物，ACID，可以替代MySQL的加强版的数据库，可以通过Mycat调用多个分库分表

 逻辑库——通过逻辑库调用底下的多个分库db_user(db_user1,db_user2)

  逻辑表——逻辑库里的表成为逻辑表

  分片表——通过拆分规则进行拆分的表 id%2把单个表拆分为两个表

  ER表——用户地址表

  全剧表——数据字典

  非分片表——门店，店员表

  节点——每个单库